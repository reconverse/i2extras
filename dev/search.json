[{"path":"http://www.reconverse.org/i2extras/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2020 Tim Taylor Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/articles/fitting_epicurves.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Fitting epicurves","text":"illustrate trend fitting functionality i2extras use simulated Ebola Virus Disease (EVD) outbreak data outbreaks package.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/articles/fitting_epicurves.html","id":"loading-relevant-packages-and-data","dir":"Articles","previous_headings":"Example","what":"Loading relevant packages and data","title":"Fitting epicurves","text":"example restrict first 20 weeks data:","code":"library(outbreaks) library(i2extras) #> Loading required package: incidence2 #> Loading required package: grates library(ggplot2)  raw_dat <- ebola_sim_clean$linelist dat <- incidence(     raw_dat,      date_index = \"date_of_onset\",     interval = \"week\",     groups = \"gender\" )[1:20, ] dat #> # incidence:  20 x 4 #> # count vars: date_of_onset #> # groups:     gender #>    date_index gender count_variable count #>  * <isowk>    <fct>  <chr>          <int> #>  1 2014-W15   f      date_of_onset      1 #>  2 2014-W16   m      date_of_onset      1 #>  3 2014-W17   f      date_of_onset      4 #>  4 2014-W17   m      date_of_onset      1 #>  5 2014-W18   f      date_of_onset      4 #>  6 2014-W19   f      date_of_onset      9 #>  7 2014-W19   m      date_of_onset      3 #>  8 2014-W20   f      date_of_onset      7 #>  9 2014-W20   m      date_of_onset     10 #> 10 2014-W21   f      date_of_onset      8 #> 11 2014-W21   m      date_of_onset      7 #> 12 2014-W22   f      date_of_onset      9 #> 13 2014-W22   m      date_of_onset     10 #> 14 2014-W23   f      date_of_onset     13 #> 15 2014-W23   m      date_of_onset     10 #> 16 2014-W24   f      date_of_onset      7 #> 17 2014-W24   m      date_of_onset     14 #> 18 2014-W25   f      date_of_onset     15 #> 19 2014-W25   m      date_of_onset     15 #> 20 2014-W26   f      date_of_onset     12 plot(dat, angle = 45, border_colour = \"white\")"},{"path":"http://www.reconverse.org/i2extras/dev/articles/fitting_epicurves.html","id":"modeling-incidence","dir":"Articles","previous_headings":"Example","what":"Modeling incidence","title":"Fitting epicurves","text":"can use fit_curve() fit data either poisson negative binomial regression model. output nested object class incidence2_fit methods available automatic plotting calculation growth (decay) rates doubling (halving) times.  unnest data can use unnest() (function reexported tidyr package. fit_curve() also works nicely grouped incidence2 objects. situation, return nested tibble additional columns indicate whether warning error fitting prediction stages.  provide helper functions, is_ok(), is_warning() is_error() help filter output necessary.","code":"out <- fit_curve(dat, model = \"poisson\", alpha = 0.05) out #> # A tibble: 2 × 9 #>   count_variable gender      data model estimates  fitting_warning fitting_error #>   <chr>          <fct>  <list<ti> <lis> <list>     <list>          <list>        #> 1 date_of_onset  f       [11 × 2] <glm> <trndng_p> <NULL>          <NULL>        #> 2 date_of_onset  m        [9 × 2] <glm> <trndng_p> <NULL>          <NULL>        #> # ℹ 2 more variables: prediction_warning <list>, prediction_error <list> plot(out, angle = 45, border_colour = \"white\") growth_rate(out) #> # A tibble: 2 × 10 #>   count_variable gender model      r r_lower r_upper growth_or_decay  time #>   <chr>          <fct>  <list> <dbl>   <dbl>   <dbl> <chr>           <dbl> #> 1 date_of_onset  f      <glm>  0.137  0.0698   0.206 doubling         5.07 #> 2 date_of_onset  m      <glm>  0.240  0.146    0.341 doubling         2.89 #> # ℹ 2 more variables: time_lower <dbl>, time_upper <dbl> unnest(out, estimates) #> # A tibble: 20 × 15 #>    count_variable gender           data model count date_index estimate lower_ci #>    <chr>          <fct>  <list<tibble[> <lis> <int> <isowk>       <dbl>    <dbl> #>  1 date_of_onset  f            [11 × 2] <glm>     1 2014-W15       3.27     1.90 #>  2 date_of_onset  f            [11 × 2] <glm>     4 2014-W17       4.30     2.83 #>  3 date_of_onset  f            [11 × 2] <glm>     4 2014-W18       4.93     3.44 #>  4 date_of_onset  f            [11 × 2] <glm>     9 2014-W19       5.65     4.15 #>  5 date_of_onset  f            [11 × 2] <glm>     7 2014-W20       6.47     4.99 #>  6 date_of_onset  f            [11 × 2] <glm>     8 2014-W21       7.42     5.92 #>  7 date_of_onset  f            [11 × 2] <glm>     9 2014-W22       8.51     6.90 #>  8 date_of_onset  f            [11 × 2] <glm>    13 2014-W23       9.75     7.88 #>  9 date_of_onset  f            [11 × 2] <glm>     7 2014-W24      11.2      8.82 #> 10 date_of_onset  f            [11 × 2] <glm>    15 2014-W25      12.8      9.72 #> 11 date_of_onset  f            [11 × 2] <glm>    12 2014-W26      14.7     10.6  #> 12 date_of_onset  m             [9 × 2] <glm>     1 2014-W16       2.01     1.02 #> 13 date_of_onset  m             [9 × 2] <glm>     1 2014-W17       2.56     1.43 #> 14 date_of_onset  m             [9 × 2] <glm>     3 2014-W19       4.13     2.73 #> 15 date_of_onset  m             [9 × 2] <glm>    10 2014-W20       5.25     3.75 #> 16 date_of_onset  m             [9 × 2] <glm>     7 2014-W21       6.67     5.07 #> 17 date_of_onset  m             [9 × 2] <glm>    10 2014-W22       8.48     6.69 #> 18 date_of_onset  m             [9 × 2] <glm>    10 2014-W23      10.8      8.50 #> 19 date_of_onset  m             [9 × 2] <glm>    14 2014-W24      13.7     10.4  #> 20 date_of_onset  m             [9 × 2] <glm>    15 2014-W25      17.4     12.4  #> # ℹ 7 more variables: upper_ci <dbl>, lower_pi <dbl>, upper_pi <dbl>, #> #   fitting_warning <list>, fitting_error <list>, prediction_warning <list>, #> #   prediction_error <list> grouped_dat <- incidence(     raw_dat,      date_index = \"date_of_onset\",     interval = \"week\",     groups = \"hospital\" )[1:120, ] grouped_dat #> # incidence:  120 x 4 #> # count vars: date_of_onset #> # groups:     hospital #>    date_index hospital                                     count_variable count #>  * <isowk>    <fct>                                        <chr>          <int> #>  1 2014-W15   Military Hospital                            date_of_onset      1 #>  2 2014-W16   Connaught Hospital                           date_of_onset      1 #>  3 2014-W17   NA                                           date_of_onset      2 #>  4 2014-W17   other                                        date_of_onset      3 #>  5 2014-W18   NA                                           date_of_onset      1 #>  6 2014-W18   Connaught Hospital                           date_of_onset      1 #>  7 2014-W18   Princess Christian Maternity Hospital (PCMH) date_of_onset      1 #>  8 2014-W18   Rokupa Hospital                              date_of_onset      1 #>  9 2014-W19   NA                                           date_of_onset      1 #> 10 2014-W19   Connaught Hospital                           date_of_onset      3 #> # ℹ 110 more rows  out <- fit_curve(grouped_dat, model = \"poisson\", alpha = 0.05) out #> # A tibble: 6 × 9 #>   count_variable hospital                  data model estimates  fitting_warning #>   <chr>          <fct>                 <list<t> <lis> <list>     <list>          #> 1 date_of_onset  Connaught Hospital    [22 × 2] <glm> <trndng_p> <NULL>          #> 2 date_of_onset  Military Hospital     [21 × 2] <glm> <trndng_p> <NULL>          #> 3 date_of_onset  other                 [20 × 2] <glm> <trndng_p> <NULL>          #> 4 date_of_onset  Princess Christian M… [17 × 2] <glm> <trndng_p> <NULL>          #> 5 date_of_onset  Rokupa Hospital       [18 × 2] <glm> <trndng_p> <NULL>          #> 6 date_of_onset  NA                    [22 × 2] <glm> <trndng_p> <NULL>          #> # ℹ 3 more variables: fitting_error <list>, prediction_warning <list>, #> #   prediction_error <list>  # plot with a prediction interval but not a confidence interval plot(out, ci = FALSE, pi=TRUE, angle = 45, border_colour = \"white\") growth_rate(out) #> # A tibble: 6 × 10 #>   count_variable hospital      model     r r_lower r_upper growth_or_decay  time #>   <chr>          <fct>         <lis> <dbl>   <dbl>   <dbl> <chr>           <dbl> #> 1 date_of_onset  Connaught Ho… <glm> 0.197   0.177   0.217 doubling         3.53 #> 2 date_of_onset  Military Hos… <glm> 0.173   0.147   0.200 doubling         4.00 #> 3 date_of_onset  other         <glm> 0.170   0.141   0.200 doubling         4.09 #> 4 date_of_onset  Princess Chr… <glm> 0.142   0.101   0.188 doubling         4.87 #> 5 date_of_onset  Rokupa Hospi… <glm> 0.178   0.133   0.228 doubling         3.89 #> 6 date_of_onset  NA            <glm> 0.184   0.164   0.205 doubling         3.77 #> # ℹ 2 more variables: time_lower <dbl>, time_upper <dbl> out <- fit_curve(grouped_dat, model = \"negbin\", alpha = 0.05) is_warning(out) #> # A tibble: 5 × 7 #>   count_variable hospital               data model    estimates  fitting_warning #>   <chr>          <fct>              <list<t> <list>   <list>     <list>          #> 1 date_of_onset  Connaught Hospital [22 × 2] <negbin> <trndng_p> <chr [2]>       #> 2 date_of_onset  other              [20 × 2] <negbin> <trndng_p> <chr [2]>       #> 3 date_of_onset  Princess Christia… [17 × 2] <negbin> <trndng_p> <chr [2]>       #> 4 date_of_onset  Rokupa Hospital    [18 × 2] <negbin> <trndng_p> <chr [2]>       #> 5 date_of_onset  NA                 [22 × 2] <negbin> <trndng_p> <chr [2]>       #> # ℹ 1 more variable: prediction_warning <list> unnest(is_warning(out), fitting_warning) #> # A tibble: 10 × 7 #>    count_variable hospital              data model    estimates  fitting_warning #>    <chr>          <fct>             <list<t> <list>   <list>     <chr>           #>  1 date_of_onset  Connaught Hospit… [22 × 2] <negbin> <trndng_p> iteration limi… #>  2 date_of_onset  Connaught Hospit… [22 × 2] <negbin> <trndng_p> iteration limi… #>  3 date_of_onset  other             [20 × 2] <negbin> <trndng_p> iteration limi… #>  4 date_of_onset  other             [20 × 2] <negbin> <trndng_p> iteration limi… #>  5 date_of_onset  Princess Christi… [17 × 2] <negbin> <trndng_p> iteration limi… #>  6 date_of_onset  Princess Christi… [17 × 2] <negbin> <trndng_p> iteration limi… #>  7 date_of_onset  Rokupa Hospital   [18 × 2] <negbin> <trndng_p> iteration limi… #>  8 date_of_onset  Rokupa Hospital   [18 × 2] <negbin> <trndng_p> iteration limi… #>  9 date_of_onset  NA                [22 × 2] <negbin> <trndng_p> iteration limi… #> 10 date_of_onset  NA                [22 × 2] <negbin> <trndng_p> iteration limi… #> # ℹ 1 more variable: prediction_warning <list>"},{"path":"http://www.reconverse.org/i2extras/dev/articles/fitting_epicurves.html","id":"rolling-average","dir":"Articles","previous_headings":"Example","what":"Rolling average","title":"Fitting epicurves","text":"can add rolling average, across current previous intervals, incidence2 object add_rolling_average() function:","code":"ra <- add_rolling_average(grouped_dat, n = 2L) # group observations with the 2 prior plot(ra, border_colour = \"white\", angle = 45) +     geom_line(aes(x = date_index, y = rolling_average)) #> Warning: Removed 1 row containing missing values (`geom_line()`)."},{"path":"http://www.reconverse.org/i2extras/dev/articles/peak_estimation.html","id":"bootstrapping-and-finding-peaks","dir":"Articles","previous_headings":"","what":"Bootstrapping and finding peaks","title":"Peak estimation","text":"provide functions return peak incidence data (grouped ungrouped), bootstrap incidence data, estimate confidence intervals around peak.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/articles/peak_estimation.html","id":"bootstrap","dir":"Articles","previous_headings":"Bootstrapping and finding peaks","what":"bootstrap()","title":"Peak estimation","text":"","code":"dat <- fluH7N9_china_2013 x <- incidence(dat, date_index = \"date_of_onset\", groups = \"gender\") bootstrap(x) #> # incidence:  67 x 4 #> # count vars: date_of_onset #> # groups:     gender #>    date_index gender count_variable count #>  * <date>     <fct>  <chr>          <int> #>  1 2013-02-19 m      date_of_onset      1 #>  2 2013-02-27 m      date_of_onset      2 #>  3 2013-03-07 m      date_of_onset      1 #>  4 2013-03-08 m      date_of_onset      2 #>  5 2013-03-09 f      date_of_onset      0 #>  6 2013-03-13 f      date_of_onset      2 #>  7 2013-03-17 m      date_of_onset      1 #>  8 2013-03-19 f      date_of_onset      1 #>  9 2013-03-20 f      date_of_onset      1 #> 10 2013-03-20 m      date_of_onset      3 #> # ℹ 57 more rows"},{"path":"http://www.reconverse.org/i2extras/dev/articles/peak_estimation.html","id":"find_peak","dir":"Articles","previous_headings":"Bootstrapping and finding peaks","what":"find_peak()","title":"Peak estimation","text":"","code":"dat <- fluH7N9_china_2013 x <- incidence(dat, date_index = \"date_of_onset\", groups = \"gender\")  # peaks across each group find_peak(x) #> # incidence:  2 x 4 #> # count vars: date_of_onset #> # groups:     gender #>   date_index gender count_variable count #> * <date>     <fct>  <chr>          <int> #> 1 2013-04-11 f      date_of_onset      3 #> 2 2013-04-03 m      date_of_onset      6  # peak without groupings find_peak(regroup(x)) #> # incidence:  1 x 3 #> # count vars: date_of_onset #>   date_index count_variable count #> * <date>     <chr>          <int> #> 1 2013-04-03 date_of_onset      7"},{"path":"http://www.reconverse.org/i2extras/dev/articles/peak_estimation.html","id":"estimate_peak","dir":"Articles","previous_headings":"Bootstrapping and finding peaks","what":"estimate_peak()","title":"Peak estimation","text":"Note bootstrapping approach used estimating peak time makes following assumptions: total number event known (uncertainty total incidence); dates events (zero incidence) never bootstrapped datasets; reporting assumed constant time, .e. every case equally likely reported.","code":"dat <- fluH7N9_china_2013 x <- incidence(dat, date_index = \"date_of_onset\", groups = \"province\")  # regrouping for overall peak (we suspend progress bar for markdown) estimate_peak(regroup(x), progress = FALSE) #> # A data frame: 1 × 7 #>   count_variable observed_peak observed_count bootstrap_peaks lower_ci   #>   <chr>          <date>                 <int> <list>          <date>     #> 1 date_of_onset  2013-04-03                 7 <df [100 × 1]>  2013-03-29 #> # ℹ 2 more variables: median <date>, upper_ci <date>  # across provinces estimate_peak(x, progress = FALSE) #> # A data frame: 13 × 8 #>    province  count_variable observed_peak observed_count bootstrap_peaks #>    <fct>     <chr>          <date>                 <int> <list>          #>  1 Anhui     date_of_onset  2013-03-09                 1 <df [100 × 1]>  #>  2 Beijing   date_of_onset  2013-04-11                 1 <df [100 × 1]>  #>  3 Fujian    date_of_onset  2013-04-17                 1 <df [100 × 1]>  #>  4 Guangdong date_of_onset  2013-07-27                 1 <df [100 × 1]>  #>  5 Hebei     date_of_onset  2013-07-10                 1 <df [100 × 1]>  #>  6 Henan     date_of_onset  2013-04-06                 1 <df [100 × 1]>  #>  7 Hunan     date_of_onset  2013-04-14                 1 <df [100 × 1]>  #>  8 Jiangsu   date_of_onset  2013-03-19                 2 <df [100 × 1]>  #>  9 Jiangxi   date_of_onset  2013-04-15                 1 <df [100 × 1]>  #> 10 Shandong  date_of_onset  2013-04-16                 1 <df [100 × 1]>  #> 11 Shanghai  date_of_onset  2013-04-01                 4 <df [100 × 1]>  #> 12 Taiwan    date_of_onset  2013-04-12                 1 <df [100 × 1]>  #> 13 Zhejiang  date_of_onset  2013-04-06                 5 <df [100 × 1]>  #> # ℹ 3 more variables: lower_ci <date>, median <date>, upper_ci <date>"},{"path":"http://www.reconverse.org/i2extras/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tim Taylor. Author, maintainer. Thibaut Jombart. Author.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Taylor T, Jombart T (2023). i2extras: Functions Work 'incidence2' Objects. R package version 0.2.1.9000, https://www.reconverse.org/i2extras/.","code":"@Manual{,   title = {i2extras: Functions to Work with 'incidence2' Objects},   author = {Tim Taylor and Thibaut Jombart},   year = {2023},   note = {R package version 0.2.1.9000},   url = {https://www.reconverse.org/i2extras/}, }"},{"path":"http://www.reconverse.org/i2extras/dev/index.html","id":"scope","dir":"","previous_headings":"","what":"Functions to Work with incidence2 Objects","title":"Functions to Work with incidence2 Objects","text":"i2extras adds additional functionality incidence2 package.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/index.html","id":"what-does-it-do","dir":"","previous_headings":"","what":"What does it do?","title":"Functions to Work with incidence2 Objects","text":"main features package include: fit_curve() growth_rate(): fit trend (poisson / negative binomial) incidence2 object calculate associated growth rate. add_rolling_average(): add rolling average incidence2 object. bootstrap(): generates bootstrapped incidence2 object re-sampling, replacement, original dates events. find_peak(): locates peak time epicurve. estimate_peak(): uses bootstrap estimate peak time (related confidence interval) partially observed outbreak.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/index.html","id":"installing-the-package","dir":"","previous_headings":"","what":"Installing the package","title":"Functions to Work with incidence2 Objects","text":"can install released version {i2extras} CRAN : development version {i2extras} can installed GitHub :","code":"install.packages(\"i2extras\") remotes::install_github(\"reconverse/i2extras\", build_vignettes = TRUE)"},{"path":[]},{"path":"http://www.reconverse.org/i2extras/dev/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Functions to Work with incidence2 Objects","text":"overview i2extras provided included vignettes: vignette(\"peak_estimation\", package = \"i2extras\") vignette(\"fitting_epicurves\", package = \"i2extras\")","code":""},{"path":"http://www.reconverse.org/i2extras/dev/index.html","id":"getting-help-online","dir":"","previous_headings":"","what":"Getting help online","title":"Functions to Work with incidence2 Objects","text":"Bug reports feature requests posted github using issue system. questions posted RECON slack channel see https://www.repidemicsconsortium.org/forum/ details join.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/add_rolling_average.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a rolling average — add_rolling_average","title":"Add a rolling average — add_rolling_average","text":"add_rolling_average() adds rolling average <incidence2> object. multiple groupings count variables present average calculated .","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/add_rolling_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a rolling average — add_rolling_average","text":"","code":"add_rolling_average(   x,   n = 3L,   complete_dates = TRUE,   align = c(\"right\", \"center\"),   colname = \"rolling_average\",   ... )"},{"path":"http://www.reconverse.org/i2extras/dev/reference/add_rolling_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a rolling average — add_rolling_average","text":"x [incidence2] object n [integer] many date groupings consider window? double vectors converted via .integer(n). complete_dates [bool] incidence2::complete_dates() called data prior adding rolling average. Defaults TRUE. align character, define rolling window covers preceding rows     (\"right\"), following rows (\"left\") centered     (\"center\"). Defaults \"right\". colname [character] name column contain rolling average. ... arguments passed incidence2::complete_dates()","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/add_rolling_average.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a rolling average — add_rolling_average","text":"input object additional column rolling average.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/add_rolling_average.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a rolling average — add_rolling_average","text":"","code":"if (requireNamespace(\"outbreaks\", quietly = TRUE)) { withAutoprint({    data(ebola_sim_clean, package = \"outbreaks\")   dat <- ebola_sim_clean$linelist   dat <- subset(dat, date_of_onset <= as.Date(\"2014-10-05\"))    inci <- incidence2::incidence(       dat,       date_index = \"date_of_onset\",       groups = \"gender\",       interval = \"isoweek\"   )    add_rolling_average(inci, n = 3L)   inci2 <- incidence2::regroup(inci)   add_rolling_average(inci2, n = 7L) }) } #> > data(ebola_sim_clean, package = \"outbreaks\") #> > dat <- ebola_sim_clean$linelist #> > dat <- subset(dat, date_of_onset <= as.Date(\"2014-10-05\")) #> > inci <- incidence2::incidence(dat, date_index = \"date_of_onset\", groups = \"gender\",  #> +     interval = \"isoweek\") #> > add_rolling_average(inci, n = 3L) #> # incidence:  52 x 5 #> # count vars: date_of_onset #> # groups:     gender #>    date_index gender count_variable count rolling_average #>  * <isowk>    <fct>  <chr>          <int>           <dbl> #>  1 2014-W15   f      date_of_onset      1          NA     #>  2 2014-W15   m      date_of_onset      0          NA     #>  3 2014-W16   f      date_of_onset      0          NA     #>  4 2014-W16   m      date_of_onset      1          NA     #>  5 2014-W17   f      date_of_onset      4           1.67  #>  6 2014-W17   m      date_of_onset      1           0.667 #>  7 2014-W18   f      date_of_onset      4           2.67  #>  8 2014-W18   m      date_of_onset      0           0.667 #>  9 2014-W19   f      date_of_onset      9           5.67  #> 10 2014-W19   m      date_of_onset      3           1.33  #> # ℹ 42 more rows #> > inci2 <- incidence2::regroup(inci) #> > add_rolling_average(inci2, n = 7L) #> # incidence:  26 x 4 #> # count vars: date_of_onset #>    date_index count_variable count rolling_average #>  * <isowk>    <chr>          <int>           <dbl> #>  1 2014-W15   date_of_onset      1           NA    #>  2 2014-W16   date_of_onset      1           NA    #>  3 2014-W17   date_of_onset      5           NA    #>  4 2014-W18   date_of_onset      4           NA    #>  5 2014-W19   date_of_onset     12           NA    #>  6 2014-W20   date_of_onset     17           NA    #>  7 2014-W21   date_of_onset     15            7.86 #>  8 2014-W22   date_of_onset     19           10.4  #>  9 2014-W23   date_of_onset     23           13.6  #> 10 2014-W24   date_of_onset     21           15.9  #> # ℹ 16 more rows"},{"path":"http://www.reconverse.org/i2extras/dev/reference/bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap incidence time series — bootstrap","title":"Bootstrap incidence time series — bootstrap","text":"function can used bootstrap [incidence2] objects. Bootstrapping done sampling replacement original input dates.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap incidence time series — bootstrap","text":"","code":"bootstrap(x, randomise_groups = FALSE)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap incidence time series — bootstrap","text":"x [incidence2] object. randomise_groups [bool] groups randomised well resampling procedure; respective group sizes preserved, can used remove group-specific temporal dynamics. FALSE (default), data resampled within groups.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/bootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap incidence time series — bootstrap","text":"[incidence2] object.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/bootstrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bootstrap incidence time series — bootstrap","text":"original data stored incidence2::incidence objects, bootstrapping achieved multinomial sampling date bins weighted relative incidence.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/bootstrap.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bootstrap incidence time series — bootstrap","text":"Thibaut Jombart, Tim Taylor","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/bootstrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap incidence time series — bootstrap","text":"","code":"if (requireNamespace(\"outbreaks\", quietly = TRUE)) {     data(fluH7N9_china_2013, package = \"outbreaks\")     i <- incidence(         fluH7N9_china_2013,         date_index = \"date_of_onset\",         groups = \"gender\"    )    bootstrap(i) } #> # incidence:  67 x 4 #> # count vars: date_of_onset #> # groups:     gender #>    date_index gender count_variable count #>  * <date>     <fct>  <chr>          <int> #>  1 2013-02-19 m      date_of_onset      0 #>  2 2013-02-27 m      date_of_onset      1 #>  3 2013-03-07 m      date_of_onset      1 #>  4 2013-03-08 m      date_of_onset      1 #>  5 2013-03-09 f      date_of_onset      0 #>  6 2013-03-13 f      date_of_onset      1 #>  7 2013-03-17 m      date_of_onset      0 #>  8 2013-03-19 f      date_of_onset      0 #>  9 2013-03-20 f      date_of_onset      3 #> 10 2013-03-20 m      date_of_onset      0 #> # ℹ 57 more rows"},{"path":"http://www.reconverse.org/i2extras/dev/reference/estimate_peak.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the peak date of an incidence curve — estimate_peak","title":"Estimate the peak date of an incidence curve — estimate_peak","text":"function can used estimate peak epidemic curve using bootstrapped samples available data.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/estimate_peak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the peak date of an incidence curve — estimate_peak","text":"","code":"estimate_peak(x, n = 100L, alpha = 0.05, first_only = TRUE, progress = TRUE)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/estimate_peak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the peak date of an incidence curve — estimate_peak","text":"x <incidence2> object. n [integer] number bootstrap datasets generated; defaults 100. [double] vectors converted via .integer(n). alpha [numeric] type 1 error chosen confidence interval; defaults 0.05. first_only [bool] first peak (date) kept. Defaults TRUE. progress [bool] progress bar displayed (default = TRUE)","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/estimate_peak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the peak date of an incidence curve — estimate_peak","text":"data frame following columns: observed_date: date peak incidence original dataset. observed_count: peak incidence original dataset. estimated: median peak time bootstrap datasets. lower_ci/upper_ci: confidence interval based bootstrap datasets. bootstrap_peaks: nested tibble containing peak times bootstrapped datasets.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/estimate_peak.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate the peak date of an incidence curve — estimate_peak","text":"Input dates resampled replacement form bootstrapped datasets; peak reported , resulting distribution peak times. ties peak incidence, first date reported. Note bootstrapping approach used estimating peak time makes following assumptions: total number event known (uncertainty total incidence) dates events (zero incidence) never bootstrapped datasets reporting assumed constant time, .e. every case equally likely reported","code":""},{"path":[]},{"path":"http://www.reconverse.org/i2extras/dev/reference/estimate_peak.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimate the peak date of an incidence curve — estimate_peak","text":"Thibaut Jombart Tim Taylor, inputs caveats Michael Höhle.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/estimate_peak.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the peak date of an incidence curve — estimate_peak","text":"","code":"if (requireNamespace(\"outbreaks\", quietly = TRUE)) {    # load data and create incidence   data(fluH7N9_china_2013, package = \"outbreaks\")   i <- incidence(fluH7N9_china_2013, date_index = \"date_of_onset\")    # find 95% CI for peak time using bootstrap   estimate_peak(i)  } #> Estimating peaks from bootstrap samples: #>    |                                                                               |                                                                      |   0%   |                                                                               |=                                                                     |   1%   |                                                                               |=                                                                     |   2%   |                                                                               |==                                                                    |   3%   |                                                                               |===                                                                   |   4%   |                                                                               |====                                                                  |   5%   |                                                                               |====                                                                  |   6%   |                                                                               |=====                                                                 |   7%   |                                                                               |======                                                                |   8%   |                                                                               |======                                                                |   9%   |                                                                               |=======                                                               |  10%   |                                                                               |========                                                              |  11%   |                                                                               |========                                                              |  12%   |                                                                               |=========                                                             |  13%   |                                                                               |==========                                                            |  14%   |                                                                               |==========                                                            |  15%   |                                                                               |===========                                                           |  16%   |                                                                               |============                                                          |  17%   |                                                                               |=============                                                         |  18%   |                                                                               |=============                                                         |  19%   |                                                                               |==============                                                        |  20%   |                                                                               |===============                                                       |  21%   |                                                                               |===============                                                       |  22%   |                                                                               |================                                                      |  23%   |                                                                               |=================                                                     |  24%   |                                                                               |==================                                                    |  25%   |                                                                               |==================                                                    |  26%   |                                                                               |===================                                                   |  27%   |                                                                               |====================                                                  |  28%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  30%   |                                                                               |======================                                                |  31%   |                                                                               |======================                                                |  32%   |                                                                               |=======================                                               |  33%   |                                                                               |========================                                              |  34%   |                                                                               |========================                                              |  35%   |                                                                               |=========================                                             |  36%   |                                                                               |==========================                                            |  37%   |                                                                               |===========================                                           |  38%   |                                                                               |===========================                                           |  39%   |                                                                               |============================                                          |  40%   |                                                                               |=============================                                         |  41%   |                                                                               |=============================                                         |  42%   |                                                                               |==============================                                        |  43%   |                                                                               |===============================                                       |  44%   |                                                                               |================================                                      |  45%   |                                                                               |================================                                      |  46%   |                                                                               |=================================                                     |  47%   |                                                                               |==================================                                    |  48%   |                                                                               |==================================                                    |  49%   |                                                                               |===================================                                   |  50%   |                                                                               |====================================                                  |  51%   |                                                                               |====================================                                  |  52%   |                                                                               |=====================================                                 |  53%   |                                                                               |======================================                                |  54%   |                                                                               |======================================                                |  55%   |                                                                               |=======================================                               |  56%   |                                                                               |========================================                              |  57%   |                                                                               |=========================================                             |  58%   |                                                                               |=========================================                             |  59%   |                                                                               |==========================================                            |  60%   |                                                                               |===========================================                           |  61%   |                                                                               |===========================================                           |  62%   |                                                                               |============================================                          |  63%   |                                                                               |=============================================                         |  64%   |                                                                               |==============================================                        |  65%   |                                                                               |==============================================                        |  66%   |                                                                               |===============================================                       |  67%   |                                                                               |================================================                      |  68%   |                                                                               |================================================                      |  69%   |                                                                               |=================================================                     |  70%   |                                                                               |==================================================                    |  71%   |                                                                               |==================================================                    |  72%   |                                                                               |===================================================                   |  73%   |                                                                               |====================================================                  |  74%   |                                                                               |====================================================                  |  75%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  77%   |                                                                               |=======================================================               |  78%   |                                                                               |=======================================================               |  79%   |                                                                               |========================================================              |  80%   |                                                                               |=========================================================             |  81%   |                                                                               |=========================================================             |  82%   |                                                                               |==========================================================            |  83%   |                                                                               |===========================================================           |  84%   |                                                                               |============================================================          |  85%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  87%   |                                                                               |==============================================================        |  88%   |                                                                               |==============================================================        |  89%   |                                                                               |===============================================================       |  90%   |                                                                               |================================================================      |  91%   |                                                                               |================================================================      |  92%   |                                                                               |=================================================================     |  93%   |                                                                               |==================================================================    |  94%   |                                                                               |==================================================================    |  95%   |                                                                               |===================================================================   |  96%   |                                                                               |====================================================================  |  97%   |                                                                               |===================================================================== |  98%   |                                                                               |===================================================================== |  99%   |                                                                               |======================================================================| 100% #>  #> # A data frame: 1 × 7 #>   count_variable observed_peak observed_count bootstrap_peaks lower_ci   #>   <chr>          <date>                 <int> <list>          <date>     #> 1 date_of_onset  2013-04-03                 7 <df [100 × 1]>  2013-03-29 #> # ℹ 2 more variables: median <date>, upper_ci <date>"},{"path":"http://www.reconverse.org/i2extras/dev/reference/find_peak.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the peak date of an incidence curve — find_peak","title":"Find the peak date of an incidence curve — find_peak","text":"function can used find peak epidemic curve stored [incidence2] object.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/find_peak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the peak date of an incidence curve — find_peak","text":"","code":"find_peak(x, complete_dates = TRUE, ...)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/find_peak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the peak date of an incidence curve — find_peak","text":"x <incidence2> object. complete_dates [bool] complete_dates() called data prior keeping first entries. Defaults TRUE. ... arguments passed complete_dates().","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/find_peak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the peak date of an incidence curve — find_peak","text":"[incidence2] object date (first) highest incidence data along count. x grouped object output peak calculated grouping.","code":""},{"path":[]},{"path":"http://www.reconverse.org/i2extras/dev/reference/find_peak.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the peak date of an incidence curve — find_peak","text":"","code":"if (requireNamespace(\"outbreaks\", quietly = TRUE)) {   # load data and create incidence   data(fluH7N9_china_2013, package = \"outbreaks\")   i <- incidence(fluH7N9_china_2013, date_index = \"date_of_onset\")   find_peak(i) } #> # incidence:  1 x 3 #> # count vars: date_of_onset #>   date_index count_variable count #> * <date>     <chr>          <int> #> 1 2013-04-03 date_of_onset      7"},{"path":"http://www.reconverse.org/i2extras/dev/reference/fit_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit an epi curve — fit_curve","title":"Fit an epi curve — fit_curve","text":"Fit epi curve","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/fit_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit an epi curve — fit_curve","text":"","code":"fit_curve(x, model = c(\"poisson\", \"negbin\"), alpha = 0.05, ...)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/fit_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit an epi curve — fit_curve","text":"x incidence2::incidence object. model [character] regression model fit (can \"poisson\" \"negbin\"). alpha [numeric] Value alpha used calculate confidence intervals; defaults 0.05 corresponds 95% confidence interval. ... Additional arguments pass stats::glm() model = \"poisson\" MASS::glm.nb() model = \"negbin\".","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/fit_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit an epi curve — fit_curve","text":"object class incidence2_fit.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/flag_low_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag low counts and set them to NAs — flag_low_counts","title":"Flag low counts and set them to NAs — flag_low_counts","text":"Low counts may genuine, can also reflect actually missing data strong -reporting. function aims detect latter flagging count certain threshold, expressed fraction median count. Setting low values NAs can useful help fitting temporal trends data, zeros / low counts can throw models (e.g. Negative Binomial GLMs).","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/flag_low_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag low counts and set them to NAs — flag_low_counts","text":"","code":"flag_low_counts(x, counts = NULL, threshold = 0.001, set_missing = TRUE)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/flag_low_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag low counts and set them to NAs — flag_low_counts","text":"x incidence2::incidence object. counts tidyselect compliant indication counts used. threshold numeric multiplier median count used threshold. Defaults 0.001, case count strictly lower 0.1% mean count flagged low count. set_missing logical indicating low counts identified replaced NAs (TRUE, default). FALSE, new logical columns flag_low suffix added, indicating entries threshold.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/flag_low_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flag low counts and set them to NAs — flag_low_counts","text":"incidence2::incidence object.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/flag_low_counts.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Flag low counts and set them to NAs — flag_low_counts","text":"Tim Taylor Thibaut Jombart","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/flag_low_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag low counts and set them to NAs — flag_low_counts","text":"","code":"if (requireNamespace(\"outbreaks\", quietly = TRUE) &&     requireNamespace(\"incidence2\", quietly = TRUE)) {   data(covid19_england_nhscalls_2020, package = \"outbreaks\")   dat <- covid19_england_nhscalls_2020   i <- incidence(dat, \"date\", interval = \"isoweek\", counts = \"count\")   plot(i)   plot(flag_low_counts(i, threshold = 0.1))   plot(flag_low_counts(i, threshold = 1), title = \"removing counts below the median\") } #> Warning: Removed 19 rows containing missing values (`position_stack()`)."},{"path":"http://www.reconverse.org/i2extras/dev/reference/growth_rate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate growth/decay rate — growth_rate","title":"Calculate growth/decay rate — growth_rate","text":"Calculate growth/decay rate","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/growth_rate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate growth/decay rate — growth_rate","text":"","code":"growth_rate(x, ...)  # S3 method for default growth_rate(x, ...)  # S3 method for incidence2_fit growth_rate(   x,   alpha = 0.05,   growth_decay_time = TRUE,   include_warnings = FALSE,   ... )"},{"path":"http://www.reconverse.org/i2extras/dev/reference/growth_rate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate growth/decay rate — growth_rate","text":"x output fit_curve(). ... currently used. alpha Value alpha used calculate confidence intervals; defaults 0.05 corresponds 95% confidence interval. growth_decay_time doubling/halving time corresponding confidence intervals added output. Default TRUE. include_warnings Include models output triggered warnings errors.  Defaults FALSE.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/growth_rate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate growth/decay rate — growth_rate","text":"Tim Taylor","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/i2extras-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"Defunct functions in package i2extras — i2extras-defunct","title":"Defunct functions in package i2extras — i2extras-defunct","text":"functions variables listed now defunct, .e. longer available.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/i2extras-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Defunct functions in package i2extras — i2extras-defunct","text":"","code":"fit_model(x, model, ...)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/i2extras-defunct.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Defunct functions in package i2extras — i2extras-defunct","text":"fit_model() generic associated functions removed version 0.2.0.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/is_okerr.html","id":null,"dir":"Reference","previous_headings":"","what":"Error handling for incidence2_fit objects — is_okerr","title":"Error handling for incidence2_fit objects — is_okerr","text":"functions used filter succesful model fits errored gave warnings.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/is_okerr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Error handling for incidence2_fit objects — is_okerr","text":"","code":"is_ok(x, ...)  # S3 method for default is_ok(x, ...)  # S3 method for incidence2_fit is_ok(x, include_warnings = FALSE, ...)  is_error(x, ...)  # S3 method for default is_error(x, ...)  # S3 method for incidence2_fit is_error(x, ...)  is_warning(x, ...)  # S3 method for default is_warning(x, ...)  # S3 method for incidence2_fit is_warning(x, ...)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/is_okerr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Error handling for incidence2_fit objects — is_okerr","text":"x output function fit_curve(). ... currently used. include_warnings Include results output triggered warnings errors.  Defaults FALSE.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/is_okerr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Error handling for incidence2_fit objects — is_okerr","text":"is_ok(): returns rows <incidence2_fit> object error (optionally produce warning). is_error(): returns rows <incidence2_fit> object errored. is_warning(): returns rows <incidence2_fit> object produced warnings.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/is_okerr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Error handling for incidence2_fit objects — is_okerr","text":"Tim Taylor","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/plot.incidence2_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a fitted epicurve — plot.incidence2_fit","title":"Plot a fitted epicurve — plot.incidence2_fit","text":"Plot fitted epicurve","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/plot.incidence2_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a fitted epicurve — plot.incidence2_fit","text":"","code":"# S3 method for incidence2_fit plot(x, include_warnings = TRUE, ci = TRUE, pi = FALSE, ...)"},{"path":"http://www.reconverse.org/i2extras/dev/reference/plot.incidence2_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a fitted epicurve — plot.incidence2_fit","text":"x incidence2_fit object created fit_curve(). include_warnings Include results plot triggered warnings errors. Defaults FALSE. ci Plot confidence intervals. Defaults TRUE. pi Plot prediction intervals. Defaults FALSE. ... Additional arguments passed incidence2::plot.incidence2() .","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/plot.incidence2_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a fitted epicurve — plot.incidence2_fit","text":"incidence plot addition fitted curve.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/plot.incidence2_fit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot a fitted epicurve — plot.incidence2_fit","text":"Tim Taylor","code":""},{"path":"http://www.reconverse.org/i2extras/dev/reference/unnest.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — unnest","title":"Objects exported from other packages — unnest","text":"objects imported packages. Follow links see documentation. tidyr unnest","code":""},{"path":[]},{"path":"http://www.reconverse.org/i2extras/dev/news/index.html","id":"i2extras-021","dir":"Changelog","previous_headings":"","what":"i2extras 0.2.1","title":"i2extras 0.2.1","text":"CRAN release: 2023-03-17 Version bump CRAN resubmission. See 0.2.0 note updates.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/news/index.html","id":"i2extras-020-not-cran","dir":"Changelog","previous_headings":"","what":"i2extras 0.2.0 (not CRAN)","title":"i2extras 0.2.0 (not CRAN)","text":"{i2extras} now explicitly ‘Depends’ upstream {incidence2} package enforces minimum version requirement upon (.e. incidence2 >= 2.0.0). fit_curve() corresponding plotting method, plot.incidence2_fit() adapted account new structure plotting methods <incidence2> objects. find_peak() now wrapper around keep_peaks() function underlying incidence2 package. add_rolling_average() longer generic function now error called <incidence2> object. now returns original input additional rolling average columns change underlying objects class. Internally code refactored make use data.table::frollmean() function arguments updated accordingly. Due changes add_rolling_average(), plot method <incidence2_rolling> objects removed. estimate_peak() can now (optionally) return multiple peaks. fit_model() now defunct error called.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/news/index.html","id":"i2extras-012","dir":"Changelog","previous_headings":"","what":"i2extras 0.1.2","title":"i2extras 0.1.2","text":"CRAN release: 2021-07-08 patch release due changes upstream incidence2 package.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/news/index.html","id":"i2extras-010","dir":"Changelog","previous_headings":"","what":"i2extras 0.1.0","title":"i2extras 0.1.0","text":"CRAN release: 2021-03-30 updated work latest version (1.0.0) incidence2 growth_rate() now include_warnings parameter match plot functionality. Added flag_low_counts() function highlight low counts specified threshold.","code":""},{"path":"http://www.reconverse.org/i2extras/dev/news/index.html","id":"i2extras-002","dir":"Changelog","previous_headings":"","what":"i2extras 0.0.2","title":"i2extras 0.0.2","text":"CRAN release: 2020-10-30 Initial release","code":""}]
